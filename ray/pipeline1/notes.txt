sudo apt-get install git-lfs
git lfs install


on fractus:
wget https://github.com/git-lfs/git-lfs/releases/download/v3.2.0/git-lfs-linux-amd64-v3.2.0.tar.gz
tar -xzf git-lfs-linux-amd64-v3.2.0.tar.gz
PATH=$PATH:/path-to/git-lfs-3.2.0/
git lfs install
git lfs version


sudo chmod -R a+rwx /mydata
cd /mydata
git clone https://huggingface.co/LinWeizheDragon/PreFLMR_ViT-L
git clone https://huggingface.co/openai/clip-vit-large-patch14

cd ~/vortex_comparisons/ray/pipeline1
git clone https://github.com/LinWeizheDragon/FLMR.git
sudo pip uninstall torch torchvision torchaudio
sudo pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

pip uninstall numpy && pip install numpy==1.26.4

pip uninstall faiss
sudo ./faiss.sh

cd FLMR
pip install -e .

cd third_party/ColBERT
pip install -e .

do the inat zip fix:

cd /mydata/EVQA
sudo apt install zip
sudo zip -FFv inat.zip --out fixed.zip
sudo unzip fixed.zip -d inat/ > /dev/null 2>&1 


IF STEP E FREEZES ON __INIT__ loading torch extension:

remmove the lock file:
cd /home/jah649/.cache/torch_extensions/py310_cu118/<problematic_extension>
rm lock


For first 3 nodes:
ray start --head --metrics-export-port=8080 --node-ip-address 10.10.1.10 --resources='{"deploy_abcd": 1}'
ray start --address 10.10.1.10:6379 --node-ip-address 10.10.1.1 --resources='{"deploy_abcd": 1}'

MIG partitions for 4th node:
sudo nvidia-smi -i 0 -mig 1
sudo reboot
sudo nvidia-smi mig -i 0 -cgi 1g.6gb -C
use nvidia-smi -L to get UUIDs

to delete, 


run ray like so:
CUDA_VISIBLE_DEVICES=MIG-9a135554-b579-5904-b2ff-082d37ad44c7,MIG-57cc5694-a482-58fe-8fa5-2fd559eccf92,MIG-cb4a71e4-9f5a-54c7-9128-36997dddfa0c,MIG-4490851e-55cf-534c-93ee-12d4d109e659  ray start --address 10.10.1.10:6379 --node-ip-address 10.10.1.9 --num-gpus=4 --resources='{"deploy_e": 4}'

To deploy ray serve:
serve shutdown -y && serve deploy serve_config.yaml

LOCUST:
HF_DATASETS_CACHE=/mydata/datasets_cache locust -f locustfile.py --users 1 --spawn-rate 2 --headless -H http://10.10.1.4:8000

Try this to fix random hanging process issue:
RAY_kill_child_processes_on_worker_exit_with_raylet_subreaper=true

to make object direct send bigger:
ray start --head --metrics-export-port=8080 --node-ip-address 10.10.1.13 --resources='{"deploy_abcd": 1}' --system-config='{"max_direct_call_object_size": 67108864}'